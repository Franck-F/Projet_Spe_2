# Plan de DÃ©veloppement Complet - Projet CAMELYON17

## ğŸ“‹ Vue d'Ensemble

**Projet** : DÃ©tection automatique de mÃ©tastases ganglionnaires - CAMELYON17  
**DurÃ©e** : 9 semaines  
**Ã‰quipe** : Groupe 5  
**Objectif** : DÃ©velopper un systÃ¨me de classification des stades pN (pN0-pN3) Ã  partir d'images histopathologiques

---

## ğŸ¯ PHASE 0 : Cadrage et Organisation (Semaine 1)

### Objectifs

- âœ… Setup du projet et de l'environnement
- âœ… ComprÃ©hension du contexte mÃ©dical
- âœ… Architecture du code mise en place

### TÃ¢ches ComplÃ©tÃ©es

- [x] Repository Git crÃ©Ã© et poussÃ© sur GitHub
- [x] Environnement UV configurÃ© (155 packages installÃ©s)
- [x] Structure du projet crÃ©Ã©e
- [x] Documentation de base (README, glossaire mÃ©dical)
- [x] Notebooks templates crÃ©Ã©s
- [x] Modules Python de base crÃ©Ã©s

### TÃ¢ches Restantes

#### 0.1 Recherche Bibliographique

- [ ] Lire 5-10 articles sur la dÃ©tection de mÃ©tastases
- [ ] Ã‰tudier le systÃ¨me de classification pN en dÃ©tail
- [ ] Comprendre les enjeux cliniques des faux nÃ©gatifs
- [ ] Documenter les findings dans `reports/bibliographie.md`

#### 0.2 TÃ©lÃ©chargement du Dataset

- [ ] S'inscrire au challenge CAMELYON17
- [ ] TÃ©lÃ©charger les donnÃ©es (WSI + annotations)
- [ ] Organiser dans `data/raw/`
- [ ] VÃ©rifier l'intÃ©gritÃ© des fichiers

#### 0.3 Planification d'Ã‰quipe

- [ ] RÃ©partir les rÃ´les et responsabilitÃ©s
- [ ] DÃ©finir les jalons hebdomadaires
- [ ] Mettre en place les rÃ©unions de suivi

### Livrables

- [x] Repository GitHub fonctionnel
- [x] Environnement de dÃ©veloppement prÃªt
- [ ] Document de bibliographie
- [ ] Dataset tÃ©lÃ©chargÃ© et organisÃ©

---

## ğŸ“Š PHASE 1 : Exploration et ComprÃ©hension des DonnÃ©es (Semaines 1-2)

### Objectifs

- Analyser le dataset CAMELYON17
- Comprendre la distribution des donnÃ©es
- Identifier les dÃ©fis techniques

### TÃ¢ches

#### 1.1 Chargement et Inspection (`notebooks/01_EDA.ipynb`)

**Fichiers Ã  implÃ©menter** :

- `src/data/loader.py` : Classes `WSILoader` et `PatchLoader`

**TÃ¢ches** :

- [ ] ImplÃ©menter `WSILoader.load_wsi()` avec OpenSlide
- [ ] ImplÃ©menter `WSILoader.extract_patches()`
- [ ] CrÃ©er un script pour lister tous les fichiers WSI
- [ ] Charger les mÃ©tadonnÃ©es (patients, hÃ´pitaux, labels)
- [ ] CrÃ©er un DataFrame rÃ©capitulatif

**Code Ã  Ã©crire** :

```python
# Dans notebooks/01_EDA.ipynb
from src.data.loader import WSILoader
import pandas as pd

# Charger les mÃ©tadonnÃ©es
metadata = pd.read_csv('../data/raw/metadata.csv')
print(f"Nombre de patients: {metadata['patient_id'].nunique()}")
print(f"Nombre de WSI: {len(metadata)}")
print(f"HÃ´pitaux: {metadata['hospital'].unique()}")
```

#### 1.2 Statistiques Descriptives

**TÃ¢ches** :

- [ ] Calculer le nombre total de patients, slides, patchs
- [ ] Analyser la distribution par hÃ´pital
- [ ] Calculer les statistiques de taille des WSI
- [ ] CrÃ©er des tableaux rÃ©capitulatifs

**Visualisations Plotly** :

- [ ] Graphique en barres : distribution par hÃ´pital
- [ ] Pie chart : ratio patients par hÃ´pital
- [ ] Histogramme : tailles des WSI

#### 1.3 Distribution des Classes

**Fichiers Ã  utiliser** :

- `src/visualization/eda_plots.py` : `plot_class_distribution()`

**TÃ¢ches** :

- [ ] Calculer le ratio normal/tumoral au niveau patch
- [ ] Analyser le dÃ©sÃ©quilibre des classes
- [ ] Distribution des stades pN au niveau patient
- [ ] CorrÃ©lation entre % patchs tumoraux et stade pN

**Visualisations** :

- [ ] Barplot : distribution normal vs tumoral
- [ ] Barplot groupÃ© : distribution par hÃ´pital et classe
- [ ] Barplot : distribution des stades pN (pN0-pN3)
- [ ] Scatter plot : % patchs tumoraux vs stade pN

#### 1.4 Visualisation des WSI

**TÃ¢ches** :

- [ ] Afficher 5-10 exemples de WSI complÃ¨tes
- [ ] Visualiser les annotations (masques tumoraux)
- [ ] Extraire et afficher des patchs reprÃ©sentatifs
- [ ] Comparer patchs normaux vs tumoraux

**Code exemple** :

```python
from src.visualization.eda_plots import plot_patch_samples

# Extraire des patchs
normal_patches = extract_patches(wsi_normal, n=10)
tumor_patches = extract_patches(wsi_tumor, n=10)

# Visualiser
fig = plot_patch_samples(
    images=normal_patches + tumor_patches,
    labels=[0]*10 + [1]*10
)
fig.show()
```

#### 1.5 Quality Check

**TÃ¢ches** :

- [ ] DÃ©tecter les patchs vides (fond blanc)
- [ ] Identifier les patchs flous
- [ ] RepÃ©rer les artefacts de numÃ©risation
- [ ] Calculer le % de patchs Ã  filtrer

### Livrables Phase 1

- [ ] Notebook `01_EDA.ipynb` complÃ©tÃ© et exÃ©cutÃ©
- [ ] Rapport d'analyse statistique (2-3 pages)
- [ ] Visualisations sauvegardÃ©es dans `results/figures/eda/`
- [ ] Liste des dÃ©fis identifiÃ©s

---

## ğŸ”§ PHASE 2 : PrÃ©paration et PrÃ©traitement (Semaines 2-3)

### Objectifs

- Normaliser la coloration H&E
- CrÃ©er un pipeline d'augmentation
- GÃ©rer le dÃ©sÃ©quilibre des classes
- PrÃ©parer les datasets train/val/test

### TÃ¢ches

#### 2.1 Normalisation de Coloration (`notebooks/02_preprocessing.ipynb`)

**Fichiers Ã  implÃ©menter** :

- `src/data/preprocessing.py` : Classe `StainNormalizer`

**TÃ¢ches** :

- [ ] ImplÃ©menter normalisation Macenko
  - [ ] Calcul de la matrice de dÃ©convolution
  - [ ] Extraction des vecteurs de coloration H&E
  - [ ] Normalisation vers image de rÃ©fÃ©rence
- [ ] Alternative : implÃ©menter Reinhard
- [ ] SÃ©lectionner une image de rÃ©fÃ©rence reprÃ©sentative
- [ ] Tester sur Ã©chantillons de chaque hÃ´pital
- [ ] Comparer avant/aprÃ¨s normalisation

**Code Ã  Ã©crire** :

```python
from src.data.preprocessing import StainNormalizer

# Initialiser
normalizer = StainNormalizer(method='macenko')

# Fit sur image de rÃ©fÃ©rence
ref_image = load_reference_image()
normalizer.fit(ref_image)

# Transformer
normalized = normalizer.transform(test_image)

# Visualiser comparaison
plot_comparison(test_image, normalized)
```

**MÃ©triques** :

- [ ] Calculer la variance de coloration avant/aprÃ¨s
- [ ] Mesurer la similaritÃ© inter-hÃ´pitaux

#### 2.2 Augmentation de DonnÃ©es

**Fichiers Ã  utiliser** :

- `src/data/preprocessing.py` : `create_augmentation_pipeline()`

**TÃ¢ches** :

- [ ] Configurer les transformations dans `configs/config.yaml`
- [ ] ImplÃ©menter le pipeline Albumentations
- [ ] Tester chaque transformation individuellement
- [ ] Visualiser les effets de l'augmentation
- [ ] Valider biologiquement les transformations

**Transformations Ã  implÃ©menter** :

- [ ] Flips horizontaux/verticaux (p=0.5)
- [ ] Rotations (Â±15Â°)
- [ ] Color jitter lÃ©ger
- [ ] Gaussian blur (p=0.1)

**Validation** :

- [ ] Afficher 20 versions augmentÃ©es d'un mÃªme patch
- [ ] VÃ©rifier que les transformations sont rÃ©alistes

#### 2.3 Gestion du DÃ©sÃ©quilibre

**TÃ¢ches** :

- [ ] Calculer les poids de classes

  ```python
  from sklearn.utils.class_weight import compute_class_weight
  weights = compute_class_weight('balanced', classes=[0,1], y=labels)
  ```

- [ ] ImplÃ©menter weighted sampling
- [ ] Tester focal loss vs weighted cross-entropy
- [ ] Comparer les stratÃ©gies :
  - [ ] Sous-Ã©chantillonnage classe majoritaire
  - [ ] Sur-Ã©chantillonnage classe minoritaire
  - [ ] PondÃ©ration dans la loss
  - [ ] Combinaison des approches

#### 2.4 Split Train/Val/Test

**Fichiers Ã  crÃ©er** :

- `scripts/create_splits.py`

**TÃ¢ches** :

- [ ] **CRUCIAL** : Stratification au niveau PATIENT
- [ ] ImplÃ©menter le split 60/20/20
- [ ] StratÃ©gie par hÃ´pital :
  - [ ] Train : HÃ´pitaux 1, 2, 3
  - [ ] Val : HÃ´pital 4
  - [ ] Test : HÃ´pital 5
- [ ] VÃ©rifier la distribution des classes dans chaque split
- [ ] Sauvegarder les splits dans `data/processed/splits/`

**Code** :

```python
from sklearn.model_selection import train_test_split

# Split au niveau patient
patients = metadata['patient_id'].unique()
train_patients, test_patients = train_test_split(
    patients, test_size=0.2, stratify=patient_labels, random_state=42
)
train_patients, val_patients = train_test_split(
    train_patients, test_size=0.25, stratify=..., random_state=42
)
```

#### 2.5 Quality Filtering

**Fichiers Ã  utiliser** :

- `src/data/preprocessing.py` : `filter_low_quality_patches()`

**TÃ¢ches** :

- [ ] ImplÃ©menter dÃ©tection de fond blanc
- [ ] ImplÃ©menter dÃ©tection de flou (Laplacian variance)
- [ ] Filtrer les patchs de mauvaise qualitÃ©
- [ ] Documenter le % de patchs filtrÃ©s

### Livrables Phase 2

- [ ] Notebook `02_preprocessing.ipynb` complÃ©tÃ©
- [ ] Pipeline de prÃ©traitement fonctionnel
- [ ] Datasets train/val/test crÃ©Ã©s et sauvegardÃ©s
- [ ] Documentation des choix mÃ©thodologiques
- [ ] Rapport de prÃ©traitement (2 pages)

---

## ğŸ§  PHASE 3 : ModÃ©lisation Niveau Patch (Semaines 3-5)

### Objectifs

- Ã‰tablir une baseline
- ImplÃ©menter transfer learning
- Optimiser les hyperparamÃ¨tres
- Atteindre de bonnes performances au niveau patch

### TÃ¢ches

#### 3.1 Baseline Model (`notebooks/03_modeling_patch.ipynb`)

**Fichiers Ã  utiliser** :

- `src/models/cnn_baseline.py` : Classe `BaselineCNN`
- `src/models/train.py` : Classe `Trainer`
- `src/data/dataset.py` : Classe `CAMELYON17Dataset`

**TÃ¢ches** :

- [ ] ImplÃ©menter `CAMELYON17Dataset.__getitem__()`
- [ ] CrÃ©er les DataLoaders
- [ ] Instancier le modÃ¨le baseline
- [ ] Configurer l'entraÃ®nement :
  - [ ] Loss : CrossEntropyLoss avec poids
  - [ ] Optimizer : Adam (lr=0.001)
  - [ ] Scheduler : ReduceLROnPlateau
- [ ] EntraÃ®ner pour 20-30 Ã©poques
- [ ] Ã‰valuer sur validation set

**Code** :

```python
from src.models.cnn_baseline import BaselineCNN
from src.models.train import Trainer
from src.data.dataset import create_dataloaders

# CrÃ©er les dataloaders
train_loader, val_loader, test_loader = create_dataloaders(
    config, train_dataset, val_dataset, test_dataset
)

# ModÃ¨le
model = BaselineCNN(num_classes=2, dropout=0.5)

# EntraÃ®nement
trainer = Trainer(model, criterion, optimizer, device='cuda')
trainer.fit(train_loader, val_loader, epochs=30)
```

**MÃ©triques Ã  calculer** :

- [ ] Accuracy, Precision, Recall, F1
- [ ] **F2-score** (pondÃ©ration recall)
- [ ] AUC-ROC, AUC-PR
- [ ] Matrice de confusion

**Objectif** : Accuracy > 85%, Recall > 90%

#### 3.2 Transfer Learning

**Fichiers Ã  utiliser** :

- `src/models/transfer_learning.py` : `get_pretrained_model()`

**ModÃ¨les Ã  tester** :

- [ ] **ResNet50**
  - [ ] Charger avec poids ImageNet
  - [ ] Geler le backbone
  - [ ] Fine-tuner la derniÃ¨re couche (10 Ã©poques)
  - [ ] DÃ©geler progressivement (10 Ã©poques supplÃ©mentaires)
- [ ] **ResNet101**
  - [ ] MÃªme procÃ©dure que ResNet50
- [ ] **EfficientNet-B3**
  - [ ] Adapter la derniÃ¨re couche
  - [ ] Fine-tuning progressif
- [ ] **DenseNet121**
  - [ ] Tester comme alternative

**Code** :

```python
from src.models.transfer_learning import get_pretrained_model, unfreeze_layers

# Phase 1 : Backbone gelÃ©
model = get_pretrained_model('resnet50', num_classes=2, freeze_backbone=True)
trainer = Trainer(model, criterion, optimizer)
trainer.fit(train_loader, val_loader, epochs=10)

# Phase 2 : DÃ©gelage progressif
unfreeze_layers(model, num_layers=-1)
optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)
trainer = Trainer(model, criterion, optimizer)
trainer.fit(train_loader, val_loader, epochs=10)
```

**Comparaison** :

- [ ] CrÃ©er un tableau comparatif des performances
- [ ] Visualiser avec `src/visualization/results_plots.py`

#### 3.3 Optimisation des HyperparamÃ¨tres

**HyperparamÃ¨tres Ã  optimiser** :

- [ ] Learning rate : [1e-5, 1e-4, 1e-3]
- [ ] Batch size : [16, 32, 64]
- [ ] Dropout : [0.3, 0.5, 0.7]
- [ ] Weight decay : [1e-5, 1e-4, 1e-3]

**MÃ©thode** :

- [ ] Grid search ou random search
- [ ] Utiliser validation set pour sÃ©lection
- [ ] Documenter les rÃ©sultats

**Code** :

```python
from sklearn.model_selection import ParameterGrid

param_grid = {
    'lr': [1e-4, 1e-3],
    'batch_size': [32, 64],
    'dropout': [0.5, 0.7]
}

results = []
for params in ParameterGrid(param_grid):
    model = get_pretrained_model('resnet50', dropout=params['dropout'])
    # EntraÃ®ner et Ã©valuer
    metrics = train_and_evaluate(model, params)
    results.append(metrics)
```

#### 3.4 Ã‰valuation Niveau Patch

**Fichiers Ã  utiliser** :

- `src/evaluation/metrics.py` : `compute_all_metrics()`, `plot_confusion_matrix()`, `plot_roc_curve()`

**TÃ¢ches** :

- [ ] Calculer toutes les mÃ©triques sur test set
- [ ] CrÃ©er la matrice de confusion
- [ ] Tracer la courbe ROC
- [ ] Tracer la courbe Precision-Recall
- [ ] Analyser les faux positifs et faux nÃ©gatifs
- [ ] Visualiser des exemples d'erreurs

**Visualisations** :

```python
from src.evaluation.metrics import compute_all_metrics, plot_confusion_matrix

# PrÃ©dictions
y_pred, y_proba = predict(model, test_loader)

# MÃ©triques
metrics = compute_all_metrics(y_true, y_pred, y_proba)
print(metrics)

# Confusion matrix
fig = plot_confusion_matrix(y_true, y_pred, class_names=['Normal', 'Tumoral'])
fig.write_html('results/figures/confusion_matrix.html')
```

### Livrables Phase 3

- [ ] Notebook `03_modeling_patch.ipynb` complÃ©tÃ©
- [ ] Meilleur modÃ¨le sauvegardÃ© dans `models/final/`
- [ ] Tableau comparatif des modÃ¨les
- [ ] Rapport de modÃ©lisation (3-4 pages)
- [ ] Visualisations des performances

**Objectif de performance** : Recall > 95%, AUC > 0.95

---

## ğŸ”— PHASE 4 : AgrÃ©gation Patch â†’ Patient (Semaines 5-6)

### Objectifs

- AgrÃ©ger les prÃ©dictions au niveau patient
- PrÃ©dire le stade pN
- Comparer diffÃ©rentes stratÃ©gies

### TÃ¢ches

#### 4.1 AgrÃ©gation Statistique (`notebooks/04_aggregation.ipynb`)

**Fichiers Ã  utiliser** :

- `src/models/aggregation.py` : Classe `StatisticalAggregator`

**TÃ¢ches** :

- [ ] ImplÃ©menter `StatisticalAggregator.aggregate()`
- [ ] DÃ©finir les seuils pour classification pN :

  ```python
  thresholds = {
      'pn0': 0.0,    # 0% de patchs tumoraux
      'pn1': 0.05,   # 5% de patchs tumoraux
      'pn2': 0.20    # 20% de patchs tumoraux
  }
  ```

- [ ] Optimiser les seuils sur validation set
- [ ] Tester diffÃ©rentes mÃ©triques d'agrÃ©gation :
  - [ ] Pourcentage de patchs tumoraux
  - [ ] ProbabilitÃ© moyenne
  - [ ] ProbabilitÃ© maximale
  - [ ] Surface tumorale totale

**Code** :

```python
from src.models.aggregation import StatisticalAggregator

aggregator = StatisticalAggregator(thresholds)

# Pour chaque patient
for patient_id in test_patients:
    # RÃ©cupÃ©rer les prÃ©dictions de tous les patchs
    patch_predictions = get_patient_predictions(patient_id)
    
    # AgrÃ©ger
    pn_stage = aggregator.aggregate(patch_predictions)
    print(f"Patient {patient_id}: pN{pn_stage}")
```

#### 4.2 ModÃ¨le ML de Second Niveau

**Fichiers Ã  utiliser** :

- `src/models/aggregation.py` : Classe `MLAggregator`

**TÃ¢ches** :

- [ ] ImplÃ©menter `MLAggregator.extract_features()`
- [ ] Features Ã  extraire :
  - [ ] % patchs tumoraux
  - [ ] ProbabilitÃ© moyenne/max/min
  - [ ] Ã‰cart-type des probabilitÃ©s
  - [ ] Nombre total de patchs tumoraux
  - [ ] Percentiles (25, 50, 75, 90)
- [ ] EntraÃ®ner XGBoost :

  ```python
  from src.models.aggregation import MLAggregator
  
  aggregator = MLAggregator(model_type='xgboost')
  
  # Extraire features pour tous les patients
  X_train = [extract_features(patient) for patient in train_patients]
  y_train = [get_pn_stage(patient) for patient in train_patients]
  
  # EntraÃ®ner
  aggregator.fit(X_train, y_train)
  ```

- [ ] Alternative : Random Forest
- [ ] Comparer les deux approches

#### 4.3 Multiple Instance Learning (Optionnel)

**TÃ¢ches** :

- [ ] ImplÃ©menter attention-based pooling
- [ ] Traiter chaque patient comme un "bag" de patchs
- [ ] Comparer avec les approches prÃ©cÃ©dentes

#### 4.4 Ã‰valuation Niveau Patient

**MÃ©triques** :

- [ ] Accuracy sur stade pN
- [ ] Cohen's Kappa (accord avec vÃ©ritÃ© terrain)
- [ ] Matrice de confusion 4x4 (pN0-pN3)
- [ ] TolÃ©rance Â±1 stage

**Visualisations** :

```python
from src.evaluation.metrics import plot_confusion_matrix

# Matrice de confusion
fig = plot_confusion_matrix(
    y_true_pn, y_pred_pn,
    class_names=['pN0', 'pN1', 'pN2', 'pN3']
)
fig.show()
```

### Livrables Phase 4

- [ ] Notebook `04_aggregation.ipynb` complÃ©tÃ©
- [ ] Comparaison des stratÃ©gies d'agrÃ©gation
- [ ] Meilleure stratÃ©gie sÃ©lectionnÃ©e et documentÃ©e
- [ ] Rapport d'agrÃ©gation (2-3 pages)

**Objectif** : Accuracy > 80% sur classification pN

---

## ğŸ“ˆ PHASE 5 : Ã‰valuation et Robustesse (Semaines 6-7)

### Objectifs

- Ã‰valuation complÃ¨te multi-niveaux
- Analyse du domain shift
- Tests de robustesse

### TÃ¢ches

#### 5.1 Ã‰valuation Multi-niveaux (`notebooks/05_evaluation.ipynb`)

**Niveau Patch** :

- [ ] Performances globales sur test set
- [ ] Performances par hÃ´pital
- [ ] Analyse de sous-groupes (si mÃ©tadonnÃ©es disponibles)

**Niveau Patient** :

- [ ] Accuracy, Kappa sur stades pN
- [ ] Matrice de confusion dÃ©taillÃ©e
- [ ] Analyse des erreurs de Â±1 stage vs Â±2 stages

**Code** :

```python
from src.evaluation.metrics import compute_all_metrics

# Niveau patch
patch_metrics = compute_all_metrics(y_true_patch, y_pred_patch, y_proba_patch)

# Niveau patient
patient_metrics = compute_all_metrics(y_true_patient, y_pred_patient)

# Afficher
print("=== Niveau Patch ===")
for metric, value in patch_metrics.items():
    print(f"{metric}: {value:.4f}")

print("\n=== Niveau Patient ===")
for metric, value in patient_metrics.items():
    print(f"{metric}: {value:.4f}")
```

#### 5.2 Analyse du Domain Shift

**TÃ¢ches** :

- [ ] Calculer les performances par hÃ´pital
- [ ] CrÃ©er un tableau comparatif
- [ ] Identifier les hÃ´pitaux "difficiles"
- [ ] Analyser les causes :
  - [ ] DiffÃ©rences de coloration
  - [ ] VariabilitÃ© des scanners
  - [ ] CaractÃ©ristiques des populations

**Visualisations** :

```python
import plotly.express as px

# Performances par hÃ´pital
hospital_metrics = []
for hospital in hospitals:
    mask = test_df['hospital'] == hospital
    metrics = compute_all_metrics(y_true[mask], y_pred[mask])
    hospital_metrics.append({
        'hospital': hospital,
        **metrics
    })

df = pd.DataFrame(hospital_metrics)
fig = px.bar(df, x='hospital', y='recall', title='Recall par HÃ´pital')
fig.show()
```

**StratÃ©gies d'amÃ©lioration** :

- [ ] Normalisation de coloration plus robuste
- [ ] Domain adaptation techniques
- [ ] EntraÃ®nement multi-domaine

#### 5.3 Analyse des Erreurs

**Faux NÃ©gatifs (CRITIQUE)** :

- [ ] Identifier tous les FN
- [ ] Visualiser les patchs mal classÃ©s
- [ ] CaractÃ©ristiques communes :
  - [ ] Micro-mÃ©tastases ?
  - [ ] Zones ambiguÃ«s ?
  - [ ] ProblÃ¨mes de qualitÃ© ?
- [ ] Proposer des amÃ©liorations

**Faux Positifs** :

- [ ] Identifier les FP
- [ ] Tissus inflammatoires confondus ?
- [ ] Artefacts de coloration ?

**Code** :

```python
from src.evaluation.interpretability import analyze_prediction_errors

# Analyser les erreurs
errors = analyze_prediction_errors(model, test_loader, num_examples=20)

# Visualiser
for error in errors:
    print(f"True: {error['true_label']}, Pred: {error['pred_label']}, "
          f"Confidence: {error['confidence']:.3f}")
    # Afficher l'image
```

#### 5.4 Tests de Robustesse

**Perturbations Ã  tester** :

- [ ] Bruit gaussien
- [ ] Flou
- [ ] Variations de contraste/luminositÃ©
- [ ] Rotations extrÃªmes

**Code** :

```python
import albumentations as A

# Pipeline de perturbations
perturbations = A.Compose([
    A.GaussianNoise(p=1.0),
    A.GaussianBlur(blur_limit=(5, 5), p=1.0),
])

# Tester
perturbed_metrics = test_robustness(model, test_loader, perturbations)
print(f"Performance avec perturbations: {perturbed_metrics}")
```

**Techniques avancÃ©es** :

- [ ] Monte Carlo Dropout pour incertitude
- [ ] Ensemble de modÃ¨les
- [ ] Test-time augmentation

### Livrables Phase 5

- [ ] Notebook `05_evaluation.ipynb` complÃ©tÃ©
- [ ] Rapport d'Ã©valuation complet (4-5 pages)
- [ ] Visualisations des performances
- [ ] Analyse critique des limites
- [ ] Propositions d'amÃ©lioration

---

## ğŸ” PHASE 6 : InterprÃ©tabilitÃ© et IA Responsable (Semaines 7-8)

### Objectifs

- Comprendre les dÃ©cisions du modÃ¨le
- Valider mÃ©dicalement les prÃ©dictions
- Discussion Ã©thique

### TÃ¢ches

#### 6.1 Grad-CAM (`notebooks/05_evaluation.ipynb`)

**Fichiers Ã  utiliser** :

- `src/evaluation/interpretability.py` : Classe `GradCAM`
- `src/visualization/heatmaps.py` : `plot_gradcam_heatmap()`

**TÃ¢ches** :

- [ ] ImplÃ©menter `GradCAM.generate_cam()`
- [ ] SÃ©lectionner 20-30 cas reprÃ©sentatifs :
  - [ ] Vrais positifs (mÃ©tastases bien dÃ©tectÃ©es)
  - [ ] Vrais nÃ©gatifs (tissus normaux)
  - [ ] Faux positifs (erreurs)
  - [ ] Faux nÃ©gatifs (mÃ©tastases manquÃ©es)
- [ ] GÃ©nÃ©rer les heatmaps
- [ ] Visualiser avec Plotly

**Code** :

```python
from src.evaluation.interpretability import GradCAM
from src.visualization.heatmaps import plot_gradcam_heatmap

# Initialiser Grad-CAM
model = load_best_model()
target_layer = model.layer4[-1]  # DerniÃ¨re couche conv
gradcam = GradCAM(model, target_layer)

# GÃ©nÃ©rer CAM
cam = gradcam.generate_cam(input_image, target_class=1)

# Visualiser
fig = plot_gradcam_heatmap(original_image, cam)
fig.write_html('results/figures/gradcam_example.html')
```

**Validation** :

- [ ] Le modÃ¨le regarde-t-il les bonnes structures ?
- [ ] Focus sur les cellules tumorales ou artefacts ?
- [ ] CohÃ©rence avec l'expertise pathologiste

#### 6.2 SHAP (Optionnel)

**TÃ¢ches** :

- [ ] Installer le groupe `interpretability` :

  ```bash
  uv sync --group interpretability
  ```

- [ ] Utiliser SHAP pour expliquer les prÃ©dictions
- [ ] Identifier les features les plus importantes

#### 6.3 Discussion Ã‰thique

**CrÃ©er** : `reports/discussion_ethique.md`

**Points Ã  aborder** :

- [ ] **Biais potentiels** :
  - [ ] DÃ©sÃ©quilibre racial/gÃ©ographique ?
  - [ ] Sur-reprÃ©sentation de certains hÃ´pitaux ?
  - [ ] Biais de sÃ©lection dans le dataset ?
- [ ] **Limites techniques** :
  - [ ] SensibilitÃ© aux variations de prÃ©paration
  - [ ] GÃ©nÃ©ralisabilitÃ© Ã  d'autres contextes
  - [ ] Cas oÃ¹ le modÃ¨le Ã©choue systÃ©matiquement
- [ ] **Positionnement clinique** :
  - [ ] Outil d'aide, pas de remplacement
  - [ ] Workflow proposÃ© (prÃ©-screening, second avis)
  - [ ] Quand demander avis humain ?
- [ ] **ConsidÃ©rations de dÃ©ploiement** :
  - [ ] Exigences rÃ©glementaires (CE, FDA)
  - [ ] IntÃ©gration dans le workflow clinique
  - [ ] Maintenance et monitoring
  - [ ] CoÃ»ts vs bÃ©nÃ©fices

#### 6.4 Cas d'Ã‰tude

**TÃ¢ches** :

- [ ] SÃ©lectionner 5-10 cas cliniques intÃ©ressants
- [ ] Documenter chaque cas :
  - [ ] Image du patch/WSI
  - [ ] PrÃ©diction du modÃ¨le
  - [ ] Heatmap Grad-CAM
  - [ ] InterprÃ©tation mÃ©dicale
  - [ ] Validation par expert (si possible)

### Livrables Phase 6

- [ ] Visualisations Grad-CAM (20-30 exemples)
- [ ] Document de discussion Ã©thique (3-4 pages)
- [ ] Cas d'Ã©tude documentÃ©s
- [ ] Recommandations pour dÃ©ploiement responsable

---

## ğŸ“ PHASE 7 : Documentation et Livrables Finaux (Semaines 8-9)

### Objectifs

- Finaliser le code et la documentation
- RÃ©diger le rapport final
- PrÃ©parer la prÃ©sentation

### TÃ¢ches

#### 7.1 Nettoyage et Documentation du Code

**TÃ¢ches** :

- [ ] Nettoyer tous les notebooks
- [ ] Ajouter docstrings complÃ¨tes
- [ ] Ajouter type hints
- [ ] Commenter les sections complexes
- [ ] VÃ©rifier la cohÃ©rence du code
- [ ] Tester la reproductibilitÃ© :

  ```bash
  # Tester sur une machine tierce
  git clone https://github.com/Franck-F/Projet_Spe_2.git
  cd Projet_Spe_2
  uv sync
  uv run jupyter lab
  # ExÃ©cuter tous les notebooks
  ```

**README.md** :

- [ ] Mettre Ã  jour avec les rÃ©sultats finaux
- [ ] Ajouter des exemples d'utilisation
- [ ] Documenter les commandes principales
- [ ] Ajouter des captures d'Ã©cran

#### 7.2 Rapport Final (Max 15 pages)

**CrÃ©er** : `reports/rapport_final.md`

**Structure** :

**1. Introduction (1 page)** :

- [ ] Contexte mÃ©dical et enjeux
- [ ] Objectifs du projet
- [ ] AperÃ§u de l'approche

**2. DonnÃ©es et PrÃ©traitement (2 pages)** :

- [ ] Description CAMELYON17
- [ ] Analyse exploratoire clÃ©
- [ ] Pipeline de preprocessing
- [ ] Gestion du dÃ©sÃ©quilibre

**3. MÃ©thodologie (4 pages)** :

- [ ] Architectures CNN testÃ©es
- [ ] StratÃ©gie d'entraÃ®nement
- [ ] StratÃ©gie d'agrÃ©gation patchâ†’patient
- [ ] Choix techniques justifiÃ©s

**4. RÃ©sultats (4 pages)** :

- [ ] Performances niveau patch et patient
- [ ] Comparaison des approches
- [ ] Analyse du domain shift
- [ ] Visualisations clÃ©s (tableaux, graphiques)

**5. InterprÃ©tabilitÃ© et Discussion (3 pages)** :

- [ ] Analyse Grad-CAM
- [ ] Limites et biais
- [ ] Perspectives mÃ©dicales
- [ ] IA responsable

**6. Conclusion (1 page)** :

- [ ] SynthÃ¨se des contributions
- [ ] Recommandations
- [ ] Travaux futurs

**Annexes** :

- [ ] RÃ©sultats supplÃ©mentaires
- [ ] HyperparamÃ¨tres dÃ©taillÃ©s
- [ ] Code snippets importants

#### 7.3 PrÃ©sentation Orale (15 min)

**CrÃ©er** : `reports/presentation.pptx` ou utiliser Jupyter Slides

**Structure (15 slides)** :

1. **Titre et Ã‰quipe** (1 slide)
2. **Contexte MÃ©dical** (2 slides)
   - Cancer du sein et mÃ©tastases
   - SystÃ¨me pN et enjeux cliniques
3. **Dataset et DÃ©fis** (2 slides)
   - CAMELYON17
   - DÃ©sÃ©quilibre, domain shift
4. **Approche MÃ©thodologique** (4 slides)
   - Architecture CNN (Transfer Learning)
   - StratÃ©gie d'agrÃ©gation
   - Pipeline complet
5. **RÃ©sultats** (4 slides)
   - Performances niveau patch
   - Performances niveau patient
   - Comparaison des modÃ¨les
   - InterprÃ©tabilitÃ© (Grad-CAM)
6. **Discussion et Conclusion** (2 slides)
   - Limites
   - Perspectives cliniques
   - Recommandations

**Conseils** :

- [ ] Visuels > texte
- [ ] Animations minimales
- [ ] RÃ©pÃ©tition chronomÃ©trÃ©e (3-4 fois)
- [ ] PrÃ©paration des questions potentielles

#### 7.4 VÃ©rifications Finales

**Checklist** :

- [ ] Tous les notebooks s'exÃ©cutent sans erreur
- [ ] Code reproductible testÃ©
- [ ] Citations et rÃ©fÃ©rences correctes
- [ ] Plagiat vÃ©rifiÃ©
- [ ] Utilisation IA documentÃ©e et transparente
- [ ] Tous les membres maÃ®trisent le projet
- [ ] Rendus avant deadline

**Git** :

- [ ] Dernier commit avec tag de version :

  ```bash
  git tag -a v1.0 -m "Version finale du projet"
  git push origin v1.0
  ```

- [ ] README.md Ã  jour
- [ ] LICENSE ajoutÃ©e si nÃ©cessaire

### Livrables Phase 7

- [ ] Code final nettoyÃ© et documentÃ©
- [ ] Rapport final (PDF, 15 pages max)
- [ ] PrÃ©sentation (PPT/PDF)
- [ ] Repository GitHub complet
- [ ] VidÃ©o de dÃ©monstration (optionnel, 3-5 min)

---

## ğŸ“… CALENDRIER RÃ‰CAPITULATIF

| Semaine | Phase | Objectifs ClÃ©s | Livrables |
|---------|-------|----------------|-----------|
| **1** | Phase 0 + Phase 1 | Setup + EDA initial | Env configurÃ©, EDA notebook |
| **2** | Phase 1 + Phase 2 | EDA complet + Preprocessing | Dataset preprocessÃ© |
| **3** | Phase 2 + Phase 3 | Preprocessing + Baseline | Baseline model |
| **4** | Phase 3 | Transfer Learning | ModÃ¨les CNN entraÃ®nÃ©s |
| **5** | Phase 3 + Phase 4 | Optimisation + AgrÃ©gation | Meilleur modÃ¨le patch |
| **6** | Phase 4 + Phase 5 | AgrÃ©gation + Ã‰valuation | PrÃ©dictions patient |
| **7** | Phase 5 + Phase 6 | Robustesse + InterprÃ©tabilitÃ© | Analyse complÃ¨te |
| **8** | Phase 6 + Phase 7 | Discussion + DÃ©but rÃ©daction | Grad-CAM, Ã©thique |
| **9** | Phase 7 | Finalisation | Rapport, prÃ©sentation |

---

## ğŸ¯ OBJECTIFS DE PERFORMANCE

### Niveau Patch

- **Recall** : > 95% (prioritÃ© mÃ©dicale)
- **Precision** : > 90%
- **AUC-ROC** : > 0.95
- **F2-score** : > 0.93

### Niveau Patient

- **Accuracy stade pN** : > 80%
- **Cohen's Kappa** : > 0.75
- **TolÃ©rance Â±1 stage** : > 95%

---

## ğŸ› ï¸ OUTILS ET RESSOURCES

### DÃ©veloppement

- **IDE** : VS Code avec extensions Python, Jupyter
- **Versioning** : Git + GitHub
- **Package Manager** : UV
- **Notebooks** : Jupyter Lab

### BibliothÃ¨ques Principales

- **Deep Learning** : PyTorch, TorchVision
- **Visualisation** : Plotly, Matplotlib
- **ML** : scikit-learn, XGBoost
- **Medical Imaging** : OpenSlide
- **Tracking** : TensorBoard

### Ressources Externes

- **Dataset** : <https://camelyon17.grand-challenge.org/>
- **Documentation PyTorch** : <https://pytorch.org/docs/>
- **Plotly** : <https://plotly.com/python/>
- **Papers** : Google Scholar, arXiv

---

## âš ï¸ PIÃˆGES Ã€ Ã‰VITER

### Data Leakage

- âŒ **NE JAMAIS** mÃ©langer patchs du mÃªme patient entre train/test
- âœ… Toujours stratifier au niveau PATIENT

### Overfitting

- âŒ Ne pas sur-optimiser sur validation set
- âœ… Utiliser early stopping et rÃ©gularisation

### MÃ©triques

- âŒ Ne pas se focaliser uniquement sur accuracy
- âœ… Prioriser le recall (faux nÃ©gatifs critiques)

### InterprÃ©tabilitÃ©

- âŒ Ne pas crÃ©er une boÃ®te noire
- âœ… Toujours valider avec Grad-CAM

### DÃ©connexion Clinique

- âŒ Oublier l'objectif mÃ©dical
- âœ… Toujours penser Ã  l'utilitÃ© clinique

---

## ğŸ“š RÃ‰FÃ‰RENCES CLÃ‰S

1. **CAMELYON17 Challenge** : <https://camelyon17.grand-challenge.org/>
2. **Bejnordi et al. (2017)** : Diagnostic Assessment of Deep Learning Algorithms
3. **Liu et al. (2019)** : Detecting Cancer Metastases on Gigapixel Pathology Images
4. **Campanella et al. (2019)** : Clinical-grade computational pathology using weakly supervised deep learning

---

**Ce plan de dÃ©veloppement est votre feuille de route complÃ¨te. Suivez-le Ã©tape par Ã©tape, documentez votre progression, et n'hÃ©sitez pas Ã  adapter selon les dÃ©couvertes en cours de route. Bon courage ! ğŸš€**
