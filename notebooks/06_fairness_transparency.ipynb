{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Phase 6 : IA Responsable - √âquit√©, Transparence et Monitoring\n",
                "\n",
                "## Objectifs (Module 4)\n",
                "- Analyser l'√©quit√© du mod√®le (fairness)\n",
                "- Assurer la transparence des d√©cisions (SHAP, Grad-CAM)\n",
                "- Mettre en place le monitoring (drift detection)\n",
                "- Calculer le ROI et les KPI business\n",
                "\n",
                "**‚ö†Ô∏è IMPORTANT** : Ce notebook est OBLIGATOIRE pour le projet"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Imports\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import plotly.express as px\n",
                "import plotly.graph_objects as go\n",
                "from sklearn.metrics import confusion_matrix\n",
                "\n",
                "import sys\n",
                "sys.path.append('..')\n",
                "from src.evaluation.metrics import compute_all_metrics\n",
                "from src.utils.config import load_config\n",
                "\n",
                "config = load_config('../configs/config.yaml')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Analyse d'√âquit√© (Fairness)\n",
                "\n",
                "### Contexte\n",
                "En diagnostic m√©dical, les biais algorithmiques peuvent causer :\n",
                "- Soins in√©quitables entre groupes\n",
                "- Erreurs de diagnostic pour certaines populations\n",
                "- Perte de confiance dans le syst√®me"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 1.1 Identification des Biais Potentiels"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Charger les pr√©dictions et m√©tadonn√©es\n",
                "# TODO: Charger predictions_df avec colonnes:\n",
                "# - patient_id\n",
                "# - hospital\n",
                "# - true_pn_stage\n",
                "# - predicted_pn_stage\n",
                "# - confidence\n",
                "\n",
                "predictions_df = pd.read_csv('../results/predictions/test_predictions.csv')\n",
                "\n",
                "print(\"Distribution par h√¥pital:\")\n",
                "print(predictions_df['hospital'].value_counts())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 1.2 M√©triques de Fairness\n",
                "\n",
                "#### Demographic Parity (Parit√© D√©mographique)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Proportion de pr√©dictions positives par h√¥pital\n",
                "demographic_parity = {}\n",
                "\n",
                "for hospital in predictions_df['hospital'].unique():\n",
                "    mask = predictions_df['hospital'] == hospital\n",
                "    \n",
                "    # Proportion de patients avec m√©tastases (pN > 0)\n",
                "    positive_rate = (predictions_df[mask]['predicted_pn_stage'] > 0).mean()\n",
                "    demographic_parity[hospital] = positive_rate\n",
                "    \n",
                "    print(f\"H√¥pital {hospital}: {positive_rate:.2%} de pr√©dictions positives\")\n",
                "\n",
                "# Visualiser\n",
                "fig = px.bar(x=list(demographic_parity.keys()), \n",
                "             y=list(demographic_parity.values()),\n",
                "             title='Parit√© D√©mographique par H√¥pital',\n",
                "             labels={'x': 'H√¥pital', 'y': 'Taux de Pr√©dictions Positives'})\n",
                "fig.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Equalized Odds (√âgalit√© des Chances)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# TPR et FPR par h√¥pital\n",
                "equalized_odds = []\n",
                "\n",
                "for hospital in predictions_df['hospital'].unique():\n",
                "    mask = predictions_df['hospital'] == hospital\n",
                "    \n",
                "    # Binariser : 0 = pN0, 1 = pN1+\n",
                "    y_true_binary = (predictions_df[mask]['true_pn_stage'] > 0).astype(int)\n",
                "    y_pred_binary = (predictions_df[mask]['predicted_pn_stage'] > 0).astype(int)\n",
                "    \n",
                "    # Matrice de confusion\n",
                "    cm = confusion_matrix(y_true_binary, y_pred_binary)\n",
                "    \n",
                "    # Calculer TPR et FPR\n",
                "    tpr = cm[1,1] / (cm[1,1] + cm[1,0]) if (cm[1,1] + cm[1,0]) > 0 else 0\n",
                "    fpr = cm[0,1] / (cm[0,1] + cm[0,0]) if (cm[0,1] + cm[0,0]) > 0 else 0\n",
                "    \n",
                "    equalized_odds.append({\n",
                "        'hospital': hospital,\n",
                "        'TPR': tpr,\n",
                "        'FPR': fpr\n",
                "    })\n",
                "    \n",
                "    print(f\"H√¥pital {hospital}: TPR={tpr:.3f}, FPR={fpr:.3f}\")\n",
                "\n",
                "# Visualiser\n",
                "df_eo = pd.DataFrame(equalized_odds)\n",
                "fig = px.scatter(df_eo, x='FPR', y='TPR', text='hospital',\n",
                "                 title='Equalized Odds par H√¥pital',\n",
                "                 labels={'TPR': 'True Positive Rate', 'FPR': 'False Positive Rate'})\n",
                "fig.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 1.3 Strat√©gies de Correction\n",
                "\n",
                "#### Post-processing : Calibration par H√¥pital"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def calibrate_by_hospital(predictions_df):\n",
                "    \"\"\"\n",
                "    Ajuste les seuils de d√©cision pour chaque h√¥pital\n",
                "    pour garantir l'√©quit√© des performances\n",
                "    \"\"\"\n",
                "    calibrated_predictions = predictions_df.copy()\n",
                "    \n",
                "    for hospital in predictions_df['hospital'].unique():\n",
                "        mask = predictions_df['hospital'] == hospital\n",
                "        \n",
                "        # TODO: Optimiser le seuil pour ce h√¥pital\n",
                "        # Objectif : maximiser F1 ou minimiser FN\n",
                "        optimal_threshold = optimize_threshold_for_hospital(predictions_df[mask])\n",
                "        \n",
                "        # Appliquer le seuil calibr√©\n",
                "        calibrated_predictions.loc[mask, 'calibrated_prediction'] = \\\n",
                "            apply_calibrated_threshold(predictions_df[mask], optimal_threshold)\n",
                "    \n",
                "    return calibrated_predictions\n",
                "\n",
                "# Appliquer la calibration\n",
                "# calibrated_df = calibrate_by_hospital(predictions_df)\n",
                "# Comparer les performances avant/apr√®s"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Transparence et Explicabilit√©\n",
                "\n",
                "### 2.1 SHAP (Niveau Agr√©gation)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Installer si n√©cessaire : uv sync --group interpretability\n",
                "import shap\n",
                "\n",
                "# Charger le mod√®le d'agr√©gation (XGBoost)\n",
                "# TODO: Charger votre mod√®le XGBoost\n",
                "# xgb_model = load_model('../models/final/xgboost_aggregator.pkl')\n",
                "\n",
                "# Charger les features patients\n",
                "# X_patient_features = pd.read_csv('../data/processed/patient_features.csv')\n",
                "\n",
                "# Cr√©er l'explainer\n",
                "# explainer = shap.TreeExplainer(xgb_model)\n",
                "# shap_values = explainer.shap_values(X_patient_features)\n",
                "\n",
                "# Visualiser\n",
                "# shap.summary_plot(shap_values, X_patient_features, plot_type=\"bar\")\n",
                "# shap.summary_plot(shap_values, X_patient_features)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2.2 Grad-CAM (Niveau Patch)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from src.evaluation.interpretability import GradCAM\n",
                "from src.visualization.heatmaps import plot_gradcam_heatmap\n",
                "\n",
                "# Charger le mod√®le CNN\n",
                "# model = load_model('../models/final/resnet50_best.pth')\n",
                "\n",
                "# S√©lectionner la couche cible\n",
                "# target_layer = model.layer4[-1]  # Derni√®re couche conv\n",
                "\n",
                "# Initialiser Grad-CAM\n",
                "# gradcam = GradCAM(model, target_layer)\n",
                "\n",
                "# S√©lectionner des cas repr√©sentatifs\n",
                "# TODO: Charger 10-20 patchs (TP, TN, FP, FN)\n",
                "\n",
                "# Pour chaque patch\n",
                "# for patch, label in representative_patches:\n",
                "#     cam = gradcam.generate_cam(patch, target_class=1)\n",
                "#     fig = plot_gradcam_heatmap(patch, cam)\n",
                "#     fig.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2.3 Feature Importance"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Feature importance du mod√®le d'agr√©gation\n",
                "# feature_importance = xgb_model.feature_importances_\n",
                "# feature_names = ['tumor_percentage', 'mean_prob', 'max_prob', 'std_prob', ...]\n",
                "\n",
                "# Visualiser\n",
                "# fig = px.bar(x=feature_names, y=feature_importance,\n",
                "#              title='Importance des Features pour Pr√©diction pN',\n",
                "#              labels={'x': 'Feature', 'y': 'Importance'})\n",
                "# fig.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Monitoring et Drift Detection\n",
                "\n",
                "### 3.1 Feature Drift"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from scipy.stats import ks_2samp\n",
                "\n",
                "def detect_feature_drift(X_train, X_prod, threshold=0.05):\n",
                "    \"\"\"\n",
                "    D√©tecte le drift dans les features entre train et production\n",
                "    \"\"\"\n",
                "    drift_detected = {}\n",
                "    \n",
                "    for col in X_train.columns:\n",
                "        # Test de Kolmogorov-Smirnov\n",
                "        statistic, p_value = ks_2samp(X_train[col], X_prod[col])\n",
                "        drift_detected[col] = {\n",
                "            'p_value': p_value,\n",
                "            'drift': p_value < threshold\n",
                "        }\n",
                "    \n",
                "    return drift_detected\n",
                "\n",
                "# Simuler des donn√©es de production\n",
                "# X_train = pd.read_csv('../data/processed/train_features.csv')\n",
                "# X_prod = pd.read_csv('../data/processed/production_features.csv')\n",
                "\n",
                "# D√©tecter le drift\n",
                "# drift_results = detect_feature_drift(X_train, X_prod)\n",
                "\n",
                "# Afficher les features avec drift\n",
                "# for feature, result in drift_results.items():\n",
                "#     if result['drift']:\n",
                "#         print(f\"‚ö†Ô∏è DRIFT d√©tect√© pour {feature}: p-value={result['p_value']:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3.2 Performance Monitoring"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def monitor_performance_over_time(predictions_history):\n",
                "    \"\"\"\n",
                "    Surveille les performances dans le temps\n",
                "    \"\"\"\n",
                "    performance_metrics = []\n",
                "    \n",
                "    for batch in predictions_history:\n",
                "        metrics = compute_all_metrics(\n",
                "            batch['y_true'], \n",
                "            batch['y_pred']\n",
                "        )\n",
                "        metrics['timestamp'] = batch['timestamp']\n",
                "        performance_metrics.append(metrics)\n",
                "    \n",
                "    df_perf = pd.DataFrame(performance_metrics)\n",
                "    \n",
                "    # Visualiser l'√©volution\n",
                "    fig = px.line(df_perf, x='timestamp', y=['accuracy', 'recall', 'precision'],\n",
                "                  title='√âvolution des Performances dans le Temps')\n",
                "    fig.show()\n",
                "    \n",
                "    return df_perf\n",
                "\n",
                "# TODO: Impl√©menter avec vos donn√©es"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. ROI et KPI Business\n",
                "\n",
                "### 4.1 Calcul du ROI"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Hypoth√®ses (√† adapter selon votre contexte)\n",
                "fn_rate_manual = 0.05  # 5% de faux n√©gatifs en diagnostic manuel\n",
                "fn_rate_ai = 0.01      # 1% avec votre syst√®me IA\n",
                "cost_per_fn = 50000    # Co√ªt d'un traitement retard√© (‚Ç¨)\n",
                "n_patients_year = 10000  # Nombre de patients par an\n",
                "\n",
                "# Co√ªts du syst√®me\n",
                "development_cost = 100000  # D√©veloppement (‚Ç¨)\n",
                "deployment_cost = 20000    # D√©ploiement (‚Ç¨)\n",
                "maintenance_cost_year = 10000  # Maintenance annuelle (‚Ç¨)\n",
                "\n",
                "# Calcul des b√©n√©fices\n",
                "fn_avoided = (fn_rate_manual - fn_rate_ai) * n_patients_year\n",
                "cost_avoided_year = fn_avoided * cost_per_fn\n",
                "\n",
                "# Calcul du ROI sur 3 ans\n",
                "total_cost = development_cost + deployment_cost + (maintenance_cost_year * 3)\n",
                "total_benefit = cost_avoided_year * 3\n",
                "\n",
                "roi = ((total_benefit - total_cost) / total_cost) * 100\n",
                "\n",
                "print(\"=== Analyse ROI ===\")\n",
                "print(f\"Faux n√©gatifs √©vit√©s par an : {fn_avoided:.0f} patients\")\n",
                "print(f\"Co√ªts √©vit√©s par an : {cost_avoided_year:,.0f} ‚Ç¨\")\n",
                "print(f\"Co√ªt total du syst√®me (3 ans) : {total_cost:,.0f} ‚Ç¨\")\n",
                "print(f\"B√©n√©fice total (3 ans) : {total_benefit:,.0f} ‚Ç¨\")\n",
                "print(f\"\\nüéØ ROI sur 3 ans : {roi:.1f}%\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 4.2 KPI Business"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# D√©finir les KPI\n",
                "kpi_data = [\n",
                "    {\n",
                "        'KPI': 'Taux de d√©tection',\n",
                "        'M√©trique Technique': 'Recall',\n",
                "        'Valeur': 0.95,\n",
                "        'Objectif': 0.95,\n",
                "        'Impact': 'Moins de 5% de m√©tastases manqu√©es'\n",
                "    },\n",
                "    {\n",
                "        'KPI': 'Pr√©cision diagnostique',\n",
                "        'M√©trique Technique': 'Precision',\n",
                "        'Valeur': 0.92,\n",
                "        'Objectif': 0.90,\n",
                "        'Impact': 'Moins de 8% de faux positifs'\n",
                "    },\n",
                "    {\n",
                "        'KPI': 'Temps de traitement',\n",
                "        'M√©trique Technique': 'Temps moyen',\n",
                "        'Valeur': 3.5,  # minutes\n",
                "        'Objectif': 5.0,\n",
                "        'Impact': 'Acc√©l√©ration du diagnostic'\n",
                "    },\n",
                "]\n",
                "\n",
                "df_kpi = pd.DataFrame(kpi_data)\n",
                "print(df_kpi.to_string(index=False))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Conclusions et Recommandations\n",
                "\n",
                "### 5.1 Synth√®se des Analyses"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**√âquit√©** :\n",
                "- TODO: R√©sumer les biais identifi√©s\n",
                "- TODO: Strat√©gies de correction appliqu√©es\n",
                "- TODO: R√©sultats apr√®s correction\n",
                "\n",
                "**Transparence** :\n",
                "- TODO: Features les plus importantes identifi√©es\n",
                "- TODO: Validation m√©dicale des d√©cisions\n",
                "- TODO: Cas d'√©tude document√©s\n",
                "\n",
                "**Monitoring** :\n",
                "- TODO: Strat√©gie de drift detection d√©finie\n",
                "- TODO: Seuils d'alerte √©tablis\n",
                "- TODO: Plan de r√©entra√Ænement\n",
                "\n",
                "**Business** :\n",
                "- TODO: ROI calcul√© et justifi√©\n",
                "- TODO: KPI d√©finis et mesur√©s\n",
                "- TODO: Impact clinique quantifi√©"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 5.2 Recommandations pour le D√©ploiement"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "1. **Workflow Clinique** :\n",
                "   - Utiliser le syst√®me comme outil de pr√©-screening\n",
                "   - Validation humaine obligatoire pour cas critiques\n",
                "   - Double lecture pour cas ambigus\n",
                "\n",
                "2. **Monitoring Continu** :\n",
                "   - V√©rifier les performances hebdomadairement\n",
                "   - D√©tecter le drift mensuellement\n",
                "   - R√©entra√Æner si d√©gradation > 5%\n",
                "\n",
                "3. **√âquit√©** :\n",
                "   - Auditer les performances par h√¥pital trimestriellement\n",
                "   - Recalibrer si disparit√©s d√©tect√©es\n",
                "   - Documenter tous les ajustements\n",
                "\n",
                "4. **Transparence** :\n",
                "   - Fournir explications Grad-CAM aux pathologistes\n",
                "   - Documenter les cas d'erreur\n",
                "   - Maintenir un registre des d√©cisions"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.11.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}