# Strat√©gie de Gestion du Dataset CAMELYON17

## üö® Probl√©matiques Identifi√©es

### 1. Volume du Dataset

- **Probl√®me** : Dataset CAMELYON17 complet = plusieurs centaines de GB
- **Contraintes** :
  - Espace disque limit√©
  - Temps de t√©l√©chargement prohibitif
  - Temps de traitement tr√®s long

### 2. Biblioth√®que WILDS

- **Probl√®me** : WILDS ne fournit pas les labels pN (pN0, pN1, pN2, pN3)
- **WILDS** : Seulement classification binaire (0: pas de cancer / 1: cancer)
- **Notre besoin** : Classification multi-classe des stades pN

### 3. Absence de Dataset Nettoy√©

- **Probl√®me** : Pas de version pr√©trait√©e sur Kaggle
- **Cons√©quence** : Nous devons tout faire nous-m√™mes

---

## ‚úÖ STRAT√âGIE RECOMMAND√âE : Sous-√©chantillonnage Intelligent

### Approche Propos√©e

Au lieu d'utiliser le dataset complet, nous allons cr√©er un **sous-ensemble repr√©sentatif** du dataset CAMELYON17.

### Crit√®res de Sous-√©chantillonnage

#### 1. **Diversit√© des Centres (5 h√¥pitaux)**

```
Objectif : Garder la variabilit√© inter-hospitali√®re

Distribution propos√©e :
- Centre 1 : 20% des patients
- Centre 2 : 20% des patients
- Centre 3 : 20% des patients
- Centre 4 : 20% des patients
- Centre 5 : 20% des patients

Total : ~100-200 patients (au lieu de 1000)
```

#### 2. **√âquilibre des Stades pN**

```
Objectif : Repr√©sentation √©quitable de chaque stade

Distribution cible :
- pN0 (pas de m√©tastase)     : 30-40% (~40-60 patients)
- pN1 (m√©tastase limit√©e)    : 25-30% (~30-40 patients)
- pN2 (m√©tastase mod√©r√©e)    : 20-25% (~25-35 patients)
- pN3 (m√©tastase √©tendue)    : 15-20% (~20-30 patients)

Total : ~120-165 patients
```

#### 3. **Nombre de Patchs par Patient**

```
Objectif : G√©rer le volume de donn√©es

Strat√©gie :
- Patients pN0 : 50-100 patchs normaux
- Patients pN1-3 : 100-200 patchs (mix normal/tumoral)

Total estim√© : ~15,000-25,000 patchs (au lieu de millions)
```

---

## üìã PLAN D'ACTION D√âTAILL√â

### Phase 1 : Exploration et S√©lection (Semaine 1)

#### 1.1 Acc√®s au Dataset

**Options** :

**Option A : CAMELYON17 Challenge (Officiel)**

- Site : <https://camelyon17.grand-challenge.org/>
- Inscription requise
- T√©l√©chargement s√©lectif possible
- **Action** : S'inscrire et explorer les m√©tadonn√©es

**Option B : Kaggle (Partiel)**

- Chercher "CAMELYON17" ou "breast cancer metastasis"
- V√©rifier si des sous-ensembles existent
- **Action** : Explorer Kaggle datasets

**Option C : Papers with Code**

- Chercher des impl√©mentations existantes
- Certains auteurs partagent des sous-ensembles
- **Action** : V√©rifier les repositories GitHub

#### 1.2 T√©l√©charger les M√©tadonn√©es UNIQUEMENT

**Fichiers prioritaires** :

```
metadata/
‚îú‚îÄ‚îÄ patient_labels.csv      # Labels pN par patient
‚îú‚îÄ‚îÄ slide_info.csv          # Info sur chaque slide
‚îú‚îÄ‚îÄ patch_coordinates.csv   # Coordonn√©es des patchs
‚îî‚îÄ‚îÄ hospital_mapping.csv    # Mapping patient ‚Üí h√¥pital
```

**Script √† cr√©er** : `scripts/download_metadata.py`

```python
"""
T√©l√©charge uniquement les m√©tadonn√©es CAMELYON17
"""
import pandas as pd

# Charger les m√©tadonn√©es
patient_labels = pd.read_csv('metadata/patient_labels.csv')

# Afficher les statistiques
print("=== Distribution des stades pN ===")
print(patient_labels['pn_stage'].value_counts())

print("\n=== Distribution par h√¥pital ===")
print(patient_labels['hospital'].value_counts())
```

#### 1.3 S√©lection Stratifi√©e des Patients

**Script** : `scripts/select_patients.py`

```python
"""
S√©lection stratifi√©e de patients pour sous-√©chantillonnage
"""
import pandas as pd
from sklearn.model_selection import train_test_split

# Charger m√©tadonn√©es
df = pd.read_csv('metadata/patient_labels.csv')

# Param√®tres
N_PATIENTS_TARGET = 150  # Ajustable selon contraintes
STRATIFY_COLS = ['hospital', 'pn_stage']

# S√©lection stratifi√©e
selected_patients = []

for hospital in df['hospital'].unique():
    for pn_stage in [0, 1, 2, 3]:
        # Filtrer
        subset = df[(df['hospital'] == hospital) & (df['pn_stage'] == pn_stage)]
        
        # Nombre √† s√©lectionner (proportionnel)
        n_select = min(len(subset), N_PATIENTS_TARGET // 20)  # ~7-8 par groupe
        
        if len(subset) > 0:
            # √âchantillonnage al√©atoire
            sample = subset.sample(n=n_select, random_state=42)
            selected_patients.append(sample)

# Combiner
final_selection = pd.concat(selected_patients)

print(f"Patients s√©lectionn√©s : {len(final_selection)}")
print("\n=== Distribution finale ===")
print(final_selection.groupby(['hospital', 'pn_stage']).size())

# Sauvegarder
final_selection.to_csv('data/processed/selected_patients.csv', index=False)
```

### Phase 2 : T√©l√©chargement Cibl√© (Semaine 1-2)

#### 2.1 T√©l√©charger UNIQUEMENT les Patients S√©lectionn√©s

**Script** : `scripts/download_selected_wsi.py`

```python
"""
T√©l√©charge uniquement les WSI des patients s√©lectionn√©s
"""
import pandas as pd
import requests
from tqdm import tqdm

# Charger la s√©lection
selected = pd.read_csv('data/processed/selected_patients.csv')

# Pour chaque patient
for idx, row in tqdm(selected.iterrows(), total=len(selected)):
    patient_id = row['patient_id']
    
    # URL du fichier (√† adapter selon la source)
    url = f"https://camelyon17.org/data/{patient_id}.tif"
    
    # T√©l√©charger
    response = requests.get(url, stream=True)
    
    # Sauvegarder
    with open(f'data/raw/{patient_id}.tif', 'wb') as f:
        for chunk in response.iter_content(chunk_size=8192):
            f.write(chunk)
    
    print(f"T√©l√©charg√© : {patient_id}")
```

**Estimation de volume** :

- 150 patients √ó ~500 MB/patient = **~75 GB** (g√©rable)
- Au lieu de 1000 patients √ó 500 MB = 500 GB (ing√©rable)

#### 2.2 Extraction de Patchs

**Script** : `scripts/extract_patches.py`

```python
"""
Extrait des patchs des WSI t√©l√©charg√©es
"""
import openslide
import numpy as np
from pathlib import Path

def extract_patches_from_wsi(wsi_path, n_patches=100, patch_size=224):
    """
    Extrait n_patches de taille patch_size√ópatch_size
    """
    # Charger WSI
    slide = openslide.OpenSlide(wsi_path)
    
    # Dimensions
    width, height = slide.dimensions
    
    patches = []
    for i in range(n_patches):
        # Coordonn√©es al√©atoires
        x = np.random.randint(0, width - patch_size)
        y = np.random.randint(0, height - patch_size)
        
        # Extraire patch
        patch = slide.read_region((x, y), 0, (patch_size, patch_size))
        patch = np.array(patch.convert('RGB'))
        
        # Filtrer qualit√© (fond blanc, flou)
        if is_good_quality(patch):
            patches.append(patch)
    
    return patches

# Traiter tous les patients
for wsi_file in Path('data/raw/').glob('*.tif'):
    patches = extract_patches_from_wsi(wsi_file, n_patches=100)
    
    # Sauvegarder
    patient_id = wsi_file.stem
    save_patches(patches, f'data/processed/patches/{patient_id}/')
```

### Phase 3 : Cr√©ation du Dataset Final (Semaine 2)

#### 3.1 Organisation des Donn√©es

```
data/processed/
‚îú‚îÄ‚îÄ patches/
‚îÇ   ‚îú‚îÄ‚îÄ patient_001/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ patch_0001.png
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ patch_0002.png
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îÇ   ‚îú‚îÄ‚îÄ patient_002/
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ labels/
‚îÇ   ‚îú‚îÄ‚îÄ patch_labels.csv      # Label par patch (0: normal, 1: tumoral)
‚îÇ   ‚îî‚îÄ‚îÄ patient_labels.csv    # Label pN par patient
‚îî‚îÄ‚îÄ splits/
    ‚îú‚îÄ‚îÄ train.csv
    ‚îú‚îÄ‚îÄ val.csv
    ‚îî‚îÄ‚îÄ test.csv
```

#### 3.2 Cr√©ation des Labels

**Script** : `scripts/create_labels.py`

```python
"""
Cr√©e les fichiers de labels
"""
import pandas as pd

# Labels niveau patch
patch_labels = []
for patient_dir in Path('data/processed/patches/').iterdir():
    patient_id = patient_dir.name
    pn_stage = get_pn_stage(patient_id)  # Depuis m√©tadonn√©es
    
    for patch_file in patient_dir.glob('*.png'):
        # D√©terminer si patch est tumoral (depuis annotations)
        is_tumor = check_if_tumor(patch_file)
        
        patch_labels.append({
            'patch_id': patch_file.stem,
            'patient_id': patient_id,
            'label': int(is_tumor),
            'pn_stage': pn_stage
        })

# Sauvegarder
pd.DataFrame(patch_labels).to_csv('data/processed/labels/patch_labels.csv', index=False)
```

---

## üìä JUSTIFICATION DE LA STRAT√âGIE

### Crit√®res d'√âvaluation Attendus

Votre strat√©gie de sous-√©chantillonnage sera √©valu√©e sur :

#### 1. **Repr√©sentativit√© Statistique**

- ‚úÖ Distribution des stades pN respect√©e
- ‚úÖ Tous les centres repr√©sent√©s √©quitablement
- ‚úÖ Variabilit√© inter-hospitali√®re pr√©serv√©e

#### 2. **Rigueur M√©thodologique**

- ‚úÖ √âchantillonnage stratifi√© (pas al√©atoire simple)
- ‚úÖ Seed fix√© pour reproductibilit√©
- ‚úÖ Documentation compl√®te du processus

#### 3. **Gestion du D√©s√©quilibre**

- ‚úÖ Strat√©gies pour compenser le d√©s√©quilibre
- ‚úÖ Weighted sampling / Focal loss
- ‚úÖ Justification des choix

#### 4. **Validation de la G√©n√©ralisation**

- ‚úÖ Test sur h√¥pital hold-out
- ‚úÖ Analyse du domain shift
- ‚úÖ Robustesse d√©montr√©e

### Documentation √† Fournir

**Cr√©er** : `reports/strategie_sous_echantillonnage.md`

**Contenu** :

```markdown
# Strat√©gie de Sous-√©chantillonnage

## 1. Contraintes
- Volume du dataset complet : 500 GB
- Ressources disponibles : 100 GB
- Temps de traitement : limit√©

## 2. Approche
- S√©lection stratifi√©e de 150 patients
- Crit√®res : hospital √ó pn_stage
- Extraction de 100-200 patchs/patient

## 3. Distribution Finale
[Tableaux et graphiques]

## 4. Validation
- Split train/val/test respecte la stratification
- Analyse de repr√©sentativit√©
- Comparaison avec dataset complet (si m√©tadonn√©es disponibles)

## 5. Limites et Biais
- R√©duction de la diversit√©
- Possibles biais de s√©lection
- Strat√©gies de mitigation
```

---

## üéØ OBJECTIFS R√âVIS√âS

### Dataset Final Cible

```
Patients : 120-150
Patchs : 15,000-25,000
Volume : 50-75 GB

Distribution :
- pN0 : 35% (~45 patients, ~5,000 patchs)
- pN1 : 30% (~40 patients, ~6,000 patchs)
- pN2 : 20% (~25 patients, ~4,000 patchs)
- pN3 : 15% (~20 patients, ~3,000 patchs)

Centres : 5 h√¥pitaux √©quilibr√©s
```

### Performances Attendues

**Avec dataset r√©duit** :

- Recall niveau patch : > 90% (au lieu de 95%)
- Accuracy niveau patient : > 75% (au lieu de 80%)
- G√©n√©ralisation : √Ä d√©montrer avec analyse robuste

---

## üìù CHECKLIST DE MISE EN ≈íUVRE

### Semaine 1

- [ ] S'inscrire au challenge CAMELYON17
- [ ] T√©l√©charger les m√©tadonn√©es compl√®tes
- [ ] Analyser la distribution compl√®te
- [ ] Impl√©menter `scripts/select_patients.py`
- [ ] Valider la s√©lection stratifi√©e
- [ ] Documenter la strat√©gie

### Semaine 2

- [ ] T√©l√©charger les WSI s√©lectionn√©es (75 GB)
- [ ] Impl√©menter `scripts/extract_patches.py`
- [ ] Extraire les patchs (~20,000)
- [ ] Cr√©er les labels
- [ ] V√©rifier la qualit√© des patchs
- [ ] Cr√©er les splits train/val/test

### Semaine 3

- [ ] Finaliser le dataset
- [ ] Cr√©er le rapport de sous-√©chantillonnage
- [ ] Commencer l'EDA sur le dataset r√©duit

---

## üîÑ ALTERNATIVES SI PROBL√àMES PERSISTENT

### Plan B : Dataset Synth√©tique Partiel

- Utiliser WILDS pour la classification binaire
- Simuler les stades pN bas√©s sur % de patchs tumoraux
- **Limite** : Moins r√©aliste m√©dicalement

### Plan C : Collaboration

- Contacter d'autres √©quipes/chercheurs
- Partager un sous-ensemble d√©j√† pr√©par√©
- **Avantage** : Gain de temps

### Plan D : Dataset Alternatif

- Chercher d'autres datasets de pathologie
- Ex : PCam (PatchCamelyon) - plus petit
- **Limite** : Pas exactement le m√™me probl√®me

---

## üí° RECOMMANDATIONS FINALES

1. **Prioriser la qualit√© sur la quantit√©**
   - Mieux vaut 150 patients bien s√©lectionn√©s que 1000 mal g√©r√©s

2. **Documenter exhaustivement**
   - Chaque choix doit √™tre justifi√©
   - Transparence totale sur les limites

3. **Valider la repr√©sentativit√©**
   - Comparer avec les statistiques du dataset complet
   - D√©montrer que le sous-ensemble est repr√©sentatif

4. **Adapter les objectifs**
   - Performances l√©g√®rement inf√©rieures acceptables
   - Focus sur la m√©thodologie et l'interpr√©tabilit√©

5. **Communiquer t√¥t**
   - Informer les encadrants de la strat√©gie
   - Obtenir validation avant de commencer

---

**Cette strat√©gie transforme une contrainte (volume) en opportunit√© de d√©montrer votre rigueur m√©thodologique ! üöÄ**
