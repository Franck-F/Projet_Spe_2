# Guide de TÃ©lÃ©chargement - Dataset CAMELYON17 depuis AWS S3

## ğŸ“¦ Informations AWS

**Bucket S3** : `s3://camelyon-dataset`  
**RÃ©gion** : `us-west-2`  
**AccÃ¨s** : Public (pas de compte AWS requis)

## ğŸ¯ Objectif

TÃ©lÃ©charger un **Ã©chantillon reprÃ©sentatif** de 120-150 patients selon la stratÃ©gie de sous-Ã©chantillonnage dÃ©finie.

---

## ğŸ“‹ Ã‰tape 1 : Installation AWS CLI

### Windows

```powershell
# TÃ©lÃ©charger AWS CLI v2
# https://awscli.amazonaws.com/AWSCLIV2.msi

# Ou via winget
winget install Amazon.AWSCLI

# VÃ©rifier l'installation
aws --version
```

### Linux/macOS

```bash
# Via curl
curl "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o "awscliv2.zip"
unzip awscliv2.zip
sudo ./aws/install

# VÃ©rifier
aws --version
```

---

## Ã‰tape 2 : Explorer le Dataset

### 2.1 Lister le Contenu du Bucket

```bash
# Lister les dossiers principaux
aws s3 ls --no-sign-request s3://camelyon-dataset/

# Exemple de sortie attendue :
# PRE CAMELYON16/
# PRE CAMELYON17/
# PRE annotations/
# PRE metadata/
```

### 2.2 Explorer CAMELYON17

```bash
# Lister le contenu CAMELYON17
aws s3 ls --no-sign-request s3://camelyon-dataset/CAMELYON17/ --recursive

# Sauvegarder la liste dans un fichier
aws s3 ls --no-sign-request s3://camelyon-dataset/CAMELYON17/ --recursive > data/raw/camelyon17_file_list.txt
```

---

## Ã‰tape 3 : TÃ©lÃ©charger les MÃ©tadonnÃ©es

**Script** : `scripts/01_download_metadata.py`

```python
"""
TÃ©lÃ©charge les mÃ©tadonnÃ©es CAMELYON17 depuis AWS S3
"""
import subprocess
import pandas as pd
from pathlib import Path

# CrÃ©er les dossiers
Path('data/raw/metadata').mkdir(parents=True, exist_ok=True)

# TÃ©lÃ©charger les mÃ©tadonnÃ©es
metadata_files = [
    'patient_labels.csv',
    'slide_info.csv',
    'hospital_mapping.csv'
]

for file in metadata_files:
    s3_path = f's3://camelyon-dataset/CAMELYON17/metadata/{file}'
    local_path = f'data/raw/metadata/{file}'
    
    cmd = [
        'aws', 's3', 'cp',
        '--no-sign-request',
        s3_path,
        local_path
    ]
    
    print(f"TÃ©lÃ©chargement de {file}...")
    subprocess.run(cmd, check=True)
    print(f" {file} tÃ©lÃ©chargÃ©")

# Charger et afficher les statistiques
print("\n=== Statistiques du Dataset ===")
patient_labels = pd.read_csv('data/raw/metadata/patient_labels.csv')

print(f"Nombre total de patients : {len(patient_labels)}")
print(f"\nDistribution des stades pN :")
print(patient_labels['pn_stage'].value_counts().sort_index())

print(f"\nDistribution par hÃ´pital :")
print(patient_labels['hospital'].value_counts().sort_index())
```

**ExÃ©cution** :

```bash
uv run python scripts/01_download_metadata.py
```

---

## Ã‰tape 4 : SÃ©lection StratifiÃ©e des Patients

**Script** : `scripts/02_select_patients.py`

```python
"""
SÃ©lection stratifiÃ©e de 150 patients
CritÃ¨res : hospital Ã— pn_stage
"""
import pandas as pd
import numpy as np
from pathlib import Path

# ParamÃ¨tres
N_PATIENTS_TARGET = 150
RANDOM_SEED = 42

# Charger les mÃ©tadonnÃ©es
df = pd.read_csv('data/raw/metadata/patient_labels.csv')

print(f"Dataset complet : {len(df)} patients")
print(f"Objectif : {N_PATIENTS_TARGET} patients")

# Stratification : hospital Ã— pn_stage
selected_patients = []

# Calculer le nombre de patients par groupe
n_hospitals = df['hospital'].nunique()
n_stages = df['pn_stage'].nunique()
n_per_group = N_PATIENTS_TARGET // (n_hospitals * n_stages)

print(f"\nNombre de patients par groupe (hospital Ã— pN) : ~{n_per_group}")

# SÃ©lection stratifiÃ©e
np.random.seed(RANDOM_SEED)

for hospital in sorted(df['hospital'].unique()):
    for pn_stage in sorted(df['pn_stage'].unique()):
        # Filtrer le sous-groupe
        subset = df[(df['hospital'] == hospital) & (df['pn_stage'] == pn_stage)]
        
        if len(subset) == 0:
            continue
        
        # Nombre Ã  sÃ©lectionner
        n_select = min(len(subset), n_per_group)
        
        # Ã‰chantillonnage alÃ©atoire
        sample = subset.sample(n=n_select, random_state=RANDOM_SEED)
        selected_patients.append(sample)
        
        print(f"HÃ´pital {hospital}, pN{pn_stage}: {n_select}/{len(subset)} patients sÃ©lectionnÃ©s")

# Combiner
final_selection = pd.concat(selected_patients, ignore_index=True)

print(f"\n=== SÃ©lection Finale ===")
print(f"Total : {len(final_selection)} patients")

print(f"\nDistribution par hÃ´pital :")
print(final_selection['hospital'].value_counts().sort_index())

print(f"\nDistribution par stade pN :")
print(final_selection['pn_stage'].value_counts().sort_index())

print(f"\nDistribution croisÃ©e (hospital Ã— pN) :")
print(pd.crosstab(final_selection['hospital'], final_selection['pn_stage']))

# Sauvegarder
output_path = 'data/processed/selected_patients.csv'
Path('data/processed').mkdir(parents=True, exist_ok=True)
final_selection.to_csv(output_path, index=False)

print(f"\n SÃ©lection sauvegardÃ©e : {output_path}")
```

**ExÃ©cution** :

```bash
uv run python scripts/02_select_patients.py
```

---

## ğŸ“‹ Ã‰tape 5 : TÃ©lÃ©chargement des WSI SÃ©lectionnÃ©es

**Script** : `scripts/03_download_selected_wsi.py`

```python
"""
TÃ©lÃ©charge uniquement les WSI des patients sÃ©lectionnÃ©s
"""
import subprocess
import pandas as pd
from pathlib import Path
from tqdm import tqdm

# Charger la sÃ©lection
selected = pd.read_csv('data/processed/selected_patients.csv')

print(f"TÃ©lÃ©chargement de {len(selected)} patients...")

# CrÃ©er le dossier de destination
wsi_dir = Path('data/raw/wsi')
wsi_dir.mkdir(parents=True, exist_ok=True)

# Statistiques
total_size_gb = 0
failed_downloads = []

# Pour chaque patient
for idx, row in tqdm(selected.iterrows(), total=len(selected)):
    patient_id = row['patient_id']
    hospital = row['hospital']
    
    # Construire le chemin S3
    # Format typique : CAMELYON17/center_X/patient_XXX.tif
    s3_path = f's3://camelyon-dataset/CAMELYON17/center_{hospital}/{patient_id}.tif'
    local_path = wsi_dir / f'{patient_id}.tif'
    
    # VÃ©rifier si dÃ©jÃ  tÃ©lÃ©chargÃ©
    if local_path.exists():
        print(f"â­ï¸  {patient_id} dÃ©jÃ  tÃ©lÃ©chargÃ©")
        continue
    
    # TÃ©lÃ©charger
    cmd = [
        'aws', 's3', 'cp',
        '--no-sign-request',
        s3_path,
        str(local_path)
    ]
    
    try:
        subprocess.run(cmd, check=True, capture_output=True)
        
        # Calculer la taille
        size_mb = local_path.stat().st_size / (1024 * 1024)
        total_size_gb += size_mb / 1024
        
        print(f"âœ… {patient_id} tÃ©lÃ©chargÃ© ({size_mb:.1f} MB)")
        
    except subprocess.CalledProcessError as e:
        print(f"âŒ Erreur pour {patient_id}: {e}")
        failed_downloads.append(patient_id)

# RÃ©sumÃ©
print(f"\n=== RÃ©sumÃ© du TÃ©lÃ©chargement ===")
print(f"Patients tÃ©lÃ©chargÃ©s : {len(selected) - len(failed_downloads)}/{len(selected)}")
print(f"Taille totale : {total_size_gb:.2f} GB")

if failed_downloads:
    print(f"\nâš ï¸  Ã‰checs ({len(failed_downloads)}) :")
    for patient_id in failed_downloads:
        print(f"  - {patient_id}")
    
    # Sauvegarder la liste des Ã©checs
    pd.DataFrame({'patient_id': failed_downloads}).to_csv(
        'data/processed/failed_downloads.csv', index=False
    )
```

**ExÃ©cution** :

```bash
uv run python scripts/03_download_selected_wsi.py
```

**âš ï¸ Attention** : Ce tÃ©lÃ©chargement peut prendre plusieurs heures selon votre connexion.

---

## ğŸ“‹ Ã‰tape 6 : TÃ©lÃ©chargement ParallÃ¨le (Optionnel)

Pour accÃ©lÃ©rer le tÃ©lÃ©chargement, utilisez le tÃ©lÃ©chargement parallÃ¨le :

**Script** : `scripts/03b_download_parallel.py`

```python
"""
TÃ©lÃ©chargement parallÃ¨le avec multiprocessing
"""
import subprocess
import pandas as pd
from pathlib import Path
from multiprocessing import Pool
from tqdm import tqdm

def download_patient(args):
    """TÃ©lÃ©charge un patient"""
    patient_id, hospital, wsi_dir = args
    
    s3_path = f's3://camelyon-dataset/CAMELYON17/center_{hospital}/{patient_id}.tif'
    local_path = wsi_dir / f'{patient_id}.tif'
    
    if local_path.exists():
        return {'patient_id': patient_id, 'status': 'skipped', 'size_mb': 0}
    
    cmd = [
        'aws', 's3', 'cp',
        '--no-sign-request',
        s3_path,
        str(local_path)
    ]
    
    try:
        subprocess.run(cmd, check=True, capture_output=True)
        size_mb = local_path.stat().st_size / (1024 * 1024)
        return {'patient_id': patient_id, 'status': 'success', 'size_mb': size_mb}
    except Exception as e:
        return {'patient_id': patient_id, 'status': 'failed', 'error': str(e)}

# Charger la sÃ©lection
selected = pd.read_csv('data/processed/selected_patients.csv')
wsi_dir = Path('data/raw/wsi')
wsi_dir.mkdir(parents=True, exist_ok=True)

# PrÃ©parer les arguments
args_list = [
    (row['patient_id'], row['hospital'], wsi_dir)
    for _, row in selected.iterrows()
]

# TÃ©lÃ©chargement parallÃ¨le (4 workers)
print(f"TÃ©lÃ©chargement parallÃ¨le de {len(args_list)} patients...")

with Pool(processes=4) as pool:
    results = list(tqdm(
        pool.imap(download_patient, args_list),
        total=len(args_list)
    ))

# Analyser les rÃ©sultats
success = [r for r in results if r['status'] == 'success']
failed = [r for r in results if r['status'] == 'failed']
skipped = [r for r in results if r['status'] == 'skipped']

total_size_gb = sum(r['size_mb'] for r in success) / 1024

print(f"\n=== RÃ©sumÃ© ===")
print(f"âœ… SuccÃ¨s : {len(success)}")
print(f"â­ï¸  IgnorÃ©s : {len(skipped)}")
print(f"âŒ Ã‰checs : {len(failed)}")
print(f"ğŸ“¦ Taille totale : {total_size_gb:.2f} GB")
```

**ExÃ©cution** :

```bash
uv run python scripts/03b_download_parallel.py
```

---

## ğŸ“‹ Ã‰tape 7 : VÃ©rification de l'IntÃ©gritÃ©

**Script** : `scripts/04_verify_downloads.py`

```python
"""
VÃ©rifie l'intÃ©gritÃ© des WSI tÃ©lÃ©chargÃ©es
"""
import pandas as pd
from pathlib import Path
import openslide

# Charger la sÃ©lection
selected = pd.read_csv('data/processed/selected_patients.csv')
wsi_dir = Path('data/raw/wsi')

print("VÃ©rification de l'intÃ©gritÃ© des WSI...")

valid_wsi = []
corrupted_wsi = []

for _, row in selected.iterrows():
    patient_id = row['patient_id']
    wsi_path = wsi_dir / f'{patient_id}.tif'
    
    if not wsi_path.exists():
        print(f"âŒ {patient_id}: Fichier manquant")
        continue
    
    try:
        # Essayer d'ouvrir avec OpenSlide
        slide = openslide.OpenSlide(str(wsi_path))
        
        # VÃ©rifier les dimensions
        width, height = slide.dimensions
        
        if width > 0 and height > 0:
            valid_wsi.append({
                'patient_id': patient_id,
                'width': width,
                'height': height,
                'size_mb': wsi_path.stat().st_size / (1024 * 1024)
            })
            print(f"âœ… {patient_id}: {width}Ã—{height} pixels")
        else:
            corrupted_wsi.append(patient_id)
            print(f"âš ï¸  {patient_id}: Dimensions invalides")
        
        slide.close()
        
    except Exception as e:
        corrupted_wsi.append(patient_id)
        print(f"âŒ {patient_id}: Erreur - {e}")

# Sauvegarder les rÃ©sultats
df_valid = pd.DataFrame(valid_wsi)
df_valid.to_csv('data/processed/valid_wsi.csv', index=False)

print(f"\n=== RÃ©sumÃ© ===")
print(f"âœ… WSI valides : {len(valid_wsi)}")
print(f"âŒ WSI corrompues : {len(corrupted_wsi)}")

if corrupted_wsi:
    print(f"\nWSI Ã  retÃ©lÃ©charger :")
    for patient_id in corrupted_wsi:
        print(f"  - {patient_id}")
```

**ExÃ©cution** :

```bash
uv run python scripts/04_verify_downloads.py
```

---

## ğŸ“Š Estimation des Ressources

### Taille du Dataset

**Par patient** :

- WSI moyenne : ~500 MB
- 150 patients : **~75 GB**

### Temps de TÃ©lÃ©chargement

**Connexion 100 Mbps** :

- 75 GB â‰ˆ **1h40**

**Connexion 50 Mbps** :

- 75 GB â‰ˆ **3h20**

**Connexion 10 Mbps** :

- 75 GB â‰ˆ **16h40**

### Espace Disque Requis

```
data/
â”œâ”€â”€ raw/
â”‚   â”œâ”€â”€ wsi/              # 75 GB (WSI)
â”‚   â””â”€â”€ metadata/         # < 1 MB
â”œâ”€â”€ processed/
â”‚   â”œâ”€â”€ patches/          # 20-30 GB (patchs extraits)
â”‚   â””â”€â”€ labels/           # < 10 MB
â””â”€â”€ Total : ~100-110 GB
```

---

## âœ… Checklist de TÃ©lÃ©chargement

- [ ] AWS CLI installÃ© et vÃ©rifiÃ©
- [ ] Bucket S3 explorÃ©
- [ ] MÃ©tadonnÃ©es tÃ©lÃ©chargÃ©es
- [ ] 150 patients sÃ©lectionnÃ©s (stratification validÃ©e)
- [ ] WSI tÃ©lÃ©chargÃ©es (75 GB)
- [ ] IntÃ©gritÃ© vÃ©rifiÃ©e avec OpenSlide
- [ ] Documentation de la sÃ©lection crÃ©Ã©e

---

## ğŸ”§ DÃ©pannage

### Erreur : "Unable to locate credentials"

**Solution** : Ajouter `--no-sign-request` Ã  toutes les commandes AWS CLI

### Erreur : "Connection timeout"

**Solution** : RÃ©essayer ou utiliser le tÃ©lÃ©chargement parallÃ¨le

### Erreur : "File not found on S3"

**Solution** : VÃ©rifier le chemin S3 exact avec `aws s3 ls`

### WSI corrompue

**Solution** : RetÃ©lÃ©charger le fichier spÃ©cifique

---

## ğŸ“ Prochaines Ã‰tapes

AprÃ¨s le tÃ©lÃ©chargement :

1. **Extraction de patchs** : `scripts/05_extract_patches.py`
2. **CrÃ©ation des labels** : `scripts/06_create_labels.py`
3. **Split train/val/test** : `scripts/07_create_splits.py`

**Voir** : `PLAN_DEVELOPPEMENT.md` - Phase 2

---

**Bon tÃ©lÃ©chargement ! ğŸš€**
